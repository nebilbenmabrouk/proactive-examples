{
	"metadata": {
		"slug": "sparkorchestration",
		"name": "Spark Orchestration",
		"short_description": "Orchestrate Spark jobs from ProActive",
		"author": "ActiveEon's Team",
		"tags": ["Building blocks", "Spark", "Orchestration", "Big Data", "Analytics"],
		"version": "1.0"
	},
	"catalog" : {
		"bucket" : "big-data",
		"objects" : [
			{
				"name" : "Scala_Spark_Pi",
				"metadata" : {
					"kind": "Workflow/standard",
					"commitMessage": "First commit",
					"contentType": "application/xml"
				},
				"file" : "resources/catalog/Scala_Spark_Pi.xml"
			},
			{
				"name" : "Scala_Spark_Write_Read_HDFS",
				"metadata" : {
					"kind": "Workflow/standard",
					"commitMessage": "First commit",
					"contentType": "application/xml"
				},
				"file" : "resources/catalog/Scala_Spark_Write_Read_HDFS.xml"
			},
			{
				"name" : "Python_Spark_Pi",
				"metadata" : {
					"kind": "Workflow/standard",
					"commitMessage": "First commit",
					"contentType": "application/xml"
				},
				"file" : "resources/catalog/Python_Spark_Pi.xml"
			}
		]
	}
}
